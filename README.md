# ðŸ§  PRODIGY_GA_02 â€“ Text-to-Image Generation using Stable Diffusion

This project demonstrates the use of **pre-trained generative models** to generate images from natural language prompts using **Stable Diffusion** and the Hugging Face `diffusers` library.

The notebook runs on **Google Colab** with **GPU support**, and includes support for **batch image generation** and **automatic saving of images**.

---

## âœ… Objective

> Utilize pre-trained generative models like DALLÂ·E-mini or Stable Diffusion to create images from text prompts.

---

## ðŸ› ï¸ Technologies Used

- ðŸ¤— `diffusers`
- ðŸ¤— `transformers`
- âš¡ `accelerate`
- ðŸ”¥ `torch` (PyTorch)
- ðŸ§ª `scipy`
- ðŸ“Š `matplotlib`
- ðŸ’» Google Colab with GPU runtime

---

## ðŸ“¦ Model Details

- **Model**: `CompVis/stable-diffusion-v1-4`
- **Task**: Text-to-Image Generation
- **Input**: Text prompt
- **Output**: 512x512 Image
- **License**: [CreativeML Open RAIL-M](https://github.com/CompVis/stable-diffusion/blob/main/LICENSE)

---

## â–¶ï¸ Run This Notebook

> ðŸ”— [Open in Google Colab](https://colab.research.google.com/drive/1eyPGvdRWEJzAC9bN55ImN2tNk_y_a_iZ?usp=sharing)


