#  PRODIGY_GA_02 â€“ Text-to-Image Generation using Stable Diffusion

This project demonstrates the use of **pre-trained generative models** to generate images from natural language prompts using **Stable Diffusion** and the Hugging Face `diffusers` library.

The notebook runs on **Google Colab** with **GPU support**.

---

##  Objective

> Utilize pre-trained generative models like DALLÂ·E-mini or Stable Diffusion to create images from text prompts.

---

##  Technologies Used

-  `diffusers`
-  `transformers`
-  `accelerate`
-  `torch` (PyTorch)
-  `scipy`
-  `matplotlib`
-  Google Colab with GPU runtime

---

##  Model Details

- **Model**: `CompVis/stable-diffusion-v1-4`
- **Task**: Text-to-Image Generation
- **Input**: Text prompt
- **Output**: 512x512 Image
- **License**: [CreativeML Open RAIL-M](https://github.com/CompVis/stable-diffusion/blob/main/LICENSE)


---


##  Prompt Used

```python
prompt = "a cyberpunk futuristic cityscape at night with glowing neon signss"
````

---

##  Output

Here is the output generated by the Stable Diffusion model:

![Generated Image](Output.png)

---

##  View Notebook

You can view the output and code in the notebook here:
ðŸ”— [Open with NBViewer](https://nbviewer.org/github/Parth-349/PRODIGY_GA_02/blob/main/Output.ipynb)

---

Author
Project: PRODIGY_GA_02

Maintainer: Parth Ubhad



