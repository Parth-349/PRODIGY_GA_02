# ğŸ§  PRODIGY_GA_02 â€“ Text-to-Image Generation using Stable Diffusion

This project demonstrates the use of **pre-trained generative models** to generate images from natural language prompts using **Stable Diffusion** and the Hugging Face `diffusers` library.

The notebook runs on **Google Colab** with **GPU support**, and includes support for **batch image generation** and **automatic saving of images**.

---

## âœ… Objective

> Utilize pre-trained generative models like DALLÂ·E-mini or Stable Diffusion to create images from text prompts.

---

## ğŸ› ï¸ Technologies Used

- ğŸ¤— `diffusers`
- ğŸ¤— `transformers`
- âš¡ `accelerate`
- ğŸ”¥ `torch` (PyTorch)
- ğŸ§ª `scipy`
- ğŸ“Š `matplotlib`
- ğŸ’» Google Colab with GPU runtime

---

## ğŸ“¦ Model Details

- **Model**: `CompVis/stable-diffusion-v1-4`
- **Task**: Text-to-Image Generation
- **Input**: Text prompt
- **Output**: 512x512 Image
- **License**: [CreativeML Open RAIL-M](https://github.com/CompVis/stable-diffusion/blob/main/LICENSE)

---

Sure! Here's the corrected and well-formatted section of your `README.md` for the **Prompt Used**, **Output Image**, and **Notebook Link**.

---


## ğŸ–Œï¸ Prompt Used

```python
prompt = "a cyberpunk futuristic cityscape at night with glowing neon signss"
````

---

## ğŸ–¼ï¸ Output

Here is the output generated by the Stable Diffusion model:

![Generated Image](Output.png)

---

## ğŸ““ View Notebook

You can view the output and code in the notebook here:
ğŸ”— [Open with NBViewer](https://nbviewer.org/github/Parth-349/PRODIGY_GA_02/blob/main/Output.ipynb)




